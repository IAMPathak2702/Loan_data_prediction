# -*- coding: utf-8 -*-
"""Loan Amount Distribution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10YTmvkWV3l0A7knLhXJsJtiS_XU5Qeml

# Importing Libraries
"""

import tensorflow as tf
import sklearn as sk
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
import matplotlib.pyplot as plt
import random
import os
import seaborn as sns
import numpy as np

sns.set()
from sklearn.model_selection import train_test_split

"""# Download the data"""

df = pd.read_csv("data/loan_data_set.csv")
df

df.info()

df.columns

NUMERICAL_FEATURES = ['ApplicantIncome', 'CoapplicantIncome','Loan_Amount_Term',]

CATEGORICAL_FEATURES =['Gender', 'Married', 'Dependents', 'Education',
       'Self_Employed','Property_Area']

NUMERICAL_CATEGORICAL_FEATURES=['Credit_History']

LABEL_KEY_REG = 'LoanAmount'
LABEL_KEY_CAT = 'Loan_Status'

COLUMNS_TO_DROP=["Loan_ID"]

df.isnull().sum()   #checking missing Values

# filling with mode for categorical variables
for column in CATEGORICAL_FEATURES:
    df[column].fillna(df[column].mode()[0], inplace=True)

# filling with median for numerical variables
for column in NUMERICAL_FEATURES:
    df[column].fillna(df[column].median(), inplace=True)

for column in NUMERICAL_CATEGORICAL_FEATURES:
    df[column].fillna(df[column].median(), inplace=True)

# Filling missing values in the label column
df[LABEL_KEY_REG] = df[LABEL_KEY_REG].fillna(df[LABEL_KEY_REG].median())

df['Dependents'] = df['Dependents'].replace('3+', '3')
df['Dependents'] = df['Dependents'].astype(int)

df.isnull().sum() #rechecking missing values

df.describe(include="all").transpose() #dataframe description

df.Gender.value_counts() # Checking gender distribution for potential biases

df.Loan_Status.value_counts()

plt.figure(figsize=(1,2))

for feature in CATEGORICAL_FEATURES:
    fig = px.histogram(df, x=feature, color=feature)
    fig.update_traces(texttemplate='%{y}', textposition='outside')
    fig.update_layout(title=feature)
    fig.show()

"""### Insight: The dataset exhibits a significant gender disparity, with male applicants comprising 502 applications compared to only 112 from female applicants."""

import plotly.figure_factory as ff

plt.figure(figsize=(10,6))

for feature in NUMERICAL_FEATURES:
    plt.figure(figsize=(10,6))
    fig0 = sns.histplot(df[feature], kde=True, color="blue")
    plt.show()

corr=df.corr()
corr

plt.figure(figsize=(6,4))
corr = df.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap', fontsize=15)
plt.show()

fig = px.histogram(df, x='LoanAmount',
                   color='Gender',
                   title='Loan Amount and Gender Distribution',
                   opacity=0.8,
                   log_y=False, # represent bars with log scale
                   text_auto=True)
fig.show()

plt.figure(figsize = (10,7))
sns.scatterplot(data=df , x ='ApplicantIncome',y='CoapplicantIncome',hue ='Loan_Status')
plt.show()

fig = px.box(df, x="Education", y="ApplicantIncome",
             notched=True, # used notched shape
             title="Box plot of Education and Applicant Income",
            )
fig.show()

plt.figure(figsize=(8,6))
sns.violinplot(x='Property_Area', y='LoanAmount', data=df, palette='viridis')
plt.title('Property Area vs Loan Amount', fontsize=15)
plt.show()

plt.figure(figsize=(8,6))
sns.countplot(x='Credit_History', hue='Loan_Status', data=df, palette='pastel')
plt.title('Credit History vs Loan Status', fontsize=15)
plt.show()

plt.figure(figsize=(8,6))
sns.histplot(df['Loan_Amount_Term'], bins=20, kde=True, color='skyblue')
plt.title('Loan Amount Term Distribution', fontsize=15)
plt.xlabel('Loan Amount Term', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.show()

sns.pairplot(df)
plt.show()

plt.figure(figsize=(6,4))
df['Self_Employed'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'yellow'])
plt.title('Self Employed Distribution', fontsize=15)
plt.show()

plt.figure(figsize=(20,8))
sns.set_style("whitegrid")

colors = ["#2F9599", "#FEC601", "#EC2049"]

plt.subplot(1,3,1)
sns.boxplot(data=df, x='ApplicantIncome', color=colors[0], width=0.5)
plt.title('Applicant Income', fontsize=14)

plt.subplot(1,3,2)
sns.boxplot(data=df, x='CoapplicantIncome', color=colors[1], width=0.5)
plt.title('Coapplicant Income', fontsize=14)

plt.subplot(1,3,3)
sns.boxplot(data=df, x='LoanAmount', color=colors[2], width=0.5)
plt.title('Loan Amount', fontsize=14)

plt.suptitle('Outliers Detection', fontsize=20, y=0.95)

plt.show()

print("Before Removing the outliers", df.shape)
df = df[df['ApplicantIncome']<25000]
print("After Removing the outliers", df.shape)

print("Before Removing the outliers", df.shape)
df = df[df['CoapplicantIncome']<12000]
print("After Removing the outliers", df.shape)

print("Before Removing the outliers", df.shape)
df = df[df['LoanAmount']<400]
print("After Removing the outliers", df.shape)

fig, axes = plt.subplots(1, 3, figsize=(20, 7))

colors = ["#2F9599", "#FEC601", "#EC2049"]

sns.histplot(df['ApplicantIncome'], kde=True, color=colors[0], ax=axes[0])
axes[0].set_title('Applicant Income Distribution', fontsize=14)
axes[0].set_xlabel('Applicant Income', fontsize=12)
axes[0].set_ylabel('Frequency', fontsize=12)

sns.histplot(df['CoapplicantIncome'], kde=True, color=colors[1], ax=axes[1])
axes[1].set_title('Coapplicant Income Distribution', fontsize=14)
axes[1].set_xlabel('Coapplicant Income', fontsize=12)
axes[1].set_ylabel('Frequency', fontsize=12)

sns.histplot(df['LoanAmount'], kde=True, color=colors[2], ax=axes[2])
axes[2].set_title('Loan Amount Distribution', fontsize=14)
axes[2].set_xlabel('Loan Amount', fontsize=12)
axes[2].set_ylabel('Frequency', fontsize=12)

for ax in axes:
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

fig.suptitle('Distributions of Applicant Income, Coapplicant Income, and Loan Amount', fontsize=20)
plt.tight_layout(pad=3.0)

plt.show()

df['ApplicantIncome'] = np.log(df['ApplicantIncome'])
df['CoapplicantIncome'] = np.log1p(df['CoapplicantIncome'])

fig, axes = plt.subplots(1, 3, figsize=(20, 6))

colors = ["#66c2a5", "#fc8d62", "#8da0cb"]

sns.histplot(df['ApplicantIncome'], kde=True, color=colors[0], ax=axes[0])
axes[0].set_title('Applicant Income Distribution\n(After Log Transformation)', fontsize=14)
axes[0].set_xlabel('Applicant Income (Log Transformed)', fontsize=12)
axes[0].set_ylabel('Frequency', fontsize=12)

sns.histplot(df['CoapplicantIncome'], kde=True, color=colors[1], ax=axes[1])
axes[1].set_title('Coapplicant Income Distribution\n(After Log Transformation)', fontsize=14)
axes[1].set_xlabel('Coapplicant Income (Log Transformed)', fontsize=12)
axes[1].set_ylabel('Frequency', fontsize=12)

sns.histplot(df['LoanAmount'], kde=True, color=colors[2], ax=axes[2])
axes[2].set_title('Loan Amount Distribution', fontsize=14)
axes[2].set_xlabel('Loan Amount', fontsize=12)
axes[2].set_ylabel('Frequency', fontsize=12)

for ax in axes:
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

fig.suptitle('Distributions of Log Transformed Applicant Income, Coapplicant Income, and Original Loan Amount', fontsize=20)
plt.tight_layout(pad=3.0)

plt.show()

df.select_dtypes('object').head()

"""# BUILD Pipeline"""

df.drop(COLUMNS_TO_DROP,axis=1, inplace=True)
target = df.drop([LABEL_KEY_REG],axis=1)
labelreg = df[LABEL_KEY_REG]
labelcat = df[LABEL_KEY_REG]
X_train , X_test,y_train,y_test = train_test_split(target,labelreg , test_size=0.2, random_state=42,)
Xc_train , Xc_test,yc_train,yc_test = train_test_split(target,labelcat , test_size=0.2, random_state=42,)



for i in [X_train , X_test,y_train,y_test]:
    print(i.shape)
print("---")
for i in [Xc_train , Xc_test,yc_train,yc_test]:
    print(i.shape)

df

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def calculate_results(pipeline, X_test=X_test, y_test=y_test, mtype="reg"):
    """
    Calculate the performance metrics of a pipeline on test data.

    Parameters:
    pipeline (Pipeline): The pipeline to be evaluated.
    X_test (array-like): Test features.
    y_test (array-like): True labels for the test data.
    mtype (str): Model type, 'reg' for regression, 'class' for classification.

    Returns:
    dict: A dictionary containing the pipeline's performance metrics.
    """
    if mtype == 'reg':
        # Predict target values using the pipeline
        y_pred = pipeline.predict(X_test)

        # Calculate regression metrics
        mae = mean_absolute_error(y_test, y_pred)
        mse = mean_squared_error(y_test, y_pred)
        r_squared = r2_score(y_test, y_pred)

        # Get the name of the model
        model_name = type(pipeline.steps[-1][1]).__name__

        return {f"{model_name}": {'MAE': mae, 'MSE': mse, 'R-squared': r_squared}}

    elif mtype == "class":
        X_test=Xc_test
        y_test=yc_test

        # Predict target classes using the pipeline
        y_pred = pipeline.predict(X_test)

        # Calculate classification metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')

        # Get the name of the model
        model_name = type(pipeline.steps[-1][1]).__name__

        return {f"{model_name}": {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}}

    else:
        raise ValueError("Invalid value for mtype. Use 'reg' for regression or 'class' for classification.")

from sklearn.pipeline import Pipeline
from sklearn import set_config
set_config(display="diagram")


#feature scalling
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer

from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier , RandomForestRegressor
from sklearn.pipeline import make_pipeline

numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# Define preprocessing steps for categorical features
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Define preprocessing steps for numerical-categorical features
num_categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, NUMERICAL_FEATURES),
        ('cat', categorical_transformer, CATEGORICAL_FEATURES),
        ('num_cat', num_categorical_transformer, NUMERICAL_CATEGORICAL_FEATURES)
    ])


    # Create the full pipeline

    # loan amount prediction pipeline
pipe1 = make_pipeline(preprocessor , RandomForestRegressor(10))
pipe2 = make_pipeline(preprocessor , DecisionTreeRegressor())
pipe3 = make_pipeline(preprocessor , LinearRegression())

    # loan status prediction pipeline
pipe4 = make_pipeline(preprocessor , LogisticRegression())
pipe5 = make_pipeline(preprocessor , RandomForestClassifier())
pipe6 = make_pipeline(preprocessor , DecisionTreeClassifier())

p = RandomForestRegressor()
p.fit()



pipe1.fit(X_train,y_train)

pipe2.fit(X_train,y_train)

pipe3.fit(X_train,y_train)

pipe4.fit(Xc_train,yc_train)

pipe5.fit(Xc_train,yc_train)

pipe6.fit(Xc_train,yc_train)

calculate_results(pipe1 ,mtype="reg")

calculate_results(pipe2,mtype="reg")

calculate_results(pipe3,mtype="reg")

calculate_results(pipe4,mtype="class")

calculate_results(pipe5,mtype="class")

calculate_results(pipe6,mtype="class")

df

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report


# Set the parameters by cross-validation
tuned_parameters = [{'n_estimators': [50, 100, 200, 500],
                     'max_depth' : [5, 10, 15, 20, None],
                     'min_samples_split': [2, 5, 10],
                     'min_samples_leaf': [1, 2, 4]}]

rfc = RandomForestClassifier(random_state=42)

clf = GridSearchCV(rfc, tuned_parameters, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)

clf.fit(Xc_train, yc_train)

print("Best parameters set found on development set:")
print(clf.best_params_)

print("Detailed classification report:")
y_true, y_pred = yc_test, clf.predict(Xc_test)
print(classification_report(y_true, y_pred))